{"id":"39862488","premium":false,"billing_type":{"id":"standard","name":"Стандарт"},"relations":[],"name":"Data Platform Engineer","insider_interview":null,"response_letter_required":false,"area":{"id":"2","name":"Санкт-Петербург","url":"https://api.hh.ru/areas/2?host=hh.ru"},"salary":null,"type":{"id":"open","name":"Открытая"},"address":{"city":"Санкт-Петербург","street":"Херсонская улица","building":"12-14","description":null,"lat":59.928532,"lng":30.38105,"raw":"Санкт-Петербург, Херсонская улица, 12-14","metro":null,"metro_stations":[]},"allow_messages":true,"site":{"id":"hh","name":"hh.ru"},"experience":{"id":"between3And6","name":"От 3 до 6 лет"},"schedule":{"id":"fullDay","name":"Полный день"},"employment":{"id":"full","name":"Полная занятость"},"department":null,"contacts":null,"description":"<p>Наша платформа работы с данными построена как на проверенных решениях с открытым исходным кодом (Hadoop, Kafka, Spark, Zeppelin и не только), так и на решениях собственной разработки, заточенных под работу 24/7 в условиях высоких нагрузок. Мы ищем человека, который поможет развивать эту платформу внедряя новые решения и дорабатывая существующие.</p> <p><strong>Особенности:</strong></p> <ul> <li>big data: 4 hdfs кластера общим объемом ~50PB;</li> <li>high load: обслуживаем десятки тысяч серверов;</li> <li>high available: все сервера расположены в 5 разных дата центрах;</li> <li>не enterprise: разрабатываем решения, которые сами же и используем;</li> <li>stack: hadoop-3.1.x, kafka-2.4.x, spark-2.3.x, grafana 7.x, clickhouse, airflow</li> <li>lang: java, scala, python, bash.</li> </ul> <p><strong>Задачи:</strong></p> <ul> <li>развитие платформы хранения и обработки больших данных;</li> <li>внедрение новых инструментов для анализа данных / машинного обучения;</li> <li>разработка сервисов облегчающих работу data-science-специалистов;</li> <li>решение различных задач связанных с производительностью и отказоустойчивостью big-data-инфраструктуры;</li> <li>создание новых и поддержка рабочих пайплайнов - MapReduce, Spark, Samza;</li> <li>взаимодействие с командами DataScience и SRE;</li> <li>написание новой и дополнение уже имеющейся документации.</li> </ul> <p><strong>Требования:</strong></p> <ul> <li>готовность к самостоятельному обучению и постоянному развитию;</li> <li>понимание принципов работы локальных сетей и основных сетевых сервисов;</li> <li>знания принципов работы баз данных и распределенных систем хранения и обработки данных;</li> <li>знание Bash/Python для автоматизации процессов и Java/Scala для поддержки ETL и внедрения новых сервисов;</li> <li>опыт администрирования GNU/Linux, сборки пакетов и понимание принципов заложенных в Kerberos/SSL;</li> <li>опыт работы с системами мониторинга и инструментами для сбора метрик;</li> <li>опыт работы с со свежими версиями продуктов фонда Apache: Hadoop, Kafka, Spark, Zeppelin, Airflow, Zookeeper.</li> </ul> <p><strong>Условия:</strong></p> <ul> <li>сложные и интересные задачи: высоконагруженные быстрорастущие сервисы, которые задают уровень для конкурентов качеством и технологиями;</li> <li>оборудование: мощное железо, десятки петабайт данных, GPU-кластера и облачный инструментарий;</li> <li>команда: с нами работают профессионалы экстра класса, каждый из которых может поделиться своей экспертизой;</li> <li>профессиональное развитие: прямо в офисе мы организуем митапы, конференции, семинары и тренинги, куда открыт доступ каждому сотруднику, а также регулярно посещаем лучшие мировые конференции;</li> <li>новый опыт: лучшие сотрудники преподают в наших образовательных проектах, выступают на российских и международных конференциях;</li> <li>социальный пакет (питание, спорт, ДМС, английский язык);</li> <li>комфортный офис с парковкой, душем и зонами отдыха в паре минут от м. «Площадь Александра Невского»;</li> <li>дополнительное обучение за счет компании, участие в профессиональных конференциях и форумах по всему миру;</li> <li>корпоративные мероприятия и Team Building Events в России и за рубежом.</li> </ul>","branded_description":"\n<style type=\"text/css\">\n\t .hht-vacancydescription {\n    padding: 0px;\n}\n\n .l-cell,\n .l-paddings {\n    padding: 0px !important;\n}\n\n \n\n .b-vacancy-desc-wrapper {\n    margin-top: 0px !important;\n}\n\n .b-vacancy-desc {\n    overflow: visible !important;\n}\n\t.mail-wrapper { \n        width: 100%;\n    max-width: 690px;\n    margin: 0 auto;\n    position: relative;\n    word-break: normal;\n        font: 14px/17px Arial, Helvetica, background: #fff;\n         }\n\t.mail-content {\n    padding: 50% 17.5% 45px 17.8%;\n    position: relative;\n    min-height: 0;\n    background: url(https://hhcdn.ru/ichameleon/35049.png) 0 0 no-repeat;\n    background-size: 100% auto;\n}\n\t.mail-wrapper strong, p strong { font: bold 14px/20px Arial, Helvetica, sans-serif; color: #000;}\n\t.mail-wrapper ul {padding: 0; margin: 7px 0 0 1px;}\n\t.mail-wrapper li {padding: 0 0 0 14px; list-style: none; background: url(https://hhcdn.ru/ichameleon/35048.png) 0 6px no-repeat; font: 14px/17px Arial, Helvetica, sans-serif; color:#000;}\n\t.mail-wrapper .mail-content .g-user-content p{padding: 21px 0 0; margin: 0; font: 14px/17px Arial, Helvetica, sans-serif; color:#000;}\n\n\t.mail-wrapper .l-paddings {padding: 0;}\n\n\t/*for vacancy*/\n\t/*.apr-wrapper .paddings {padding: 0; display: inline-block;}*/\n\t/*.apr-wrapper .paddings h1{font: 14px Arial, Helvetica, sans-serif; color: #;}*/\n\n@media screen and (max-width: 699px) {\n   .mail-content {\n    padding: 50% 6.5% 25px;\n   \n}\n}\n\n</style>\n \n\n \n\t<div class=\"mail-wrapper\">\n\t\t<div class=\"mail-content\">\n\t\t\t<p>Наша платформа работы с данными построена как на проверенных решениях с открытым исходным кодом (Hadoop, Kafka, Spark, Zeppelin и не только), так и на решениях собственной разработки, заточенных под работу 24/7 в условиях высоких нагрузок. Мы ищем человека, который поможет развивать эту платформу внедряя новые решения и дорабатывая существующие.</p> <p><strong>Особенности:</strong></p> <ul> <li>big data: 4 hdfs кластера общим объемом ~50PB;</li> <li>high load: обслуживаем десятки тысяч серверов;</li> <li>high available: все сервера расположены в 5 разных дата центрах;</li> <li>не enterprise: разрабатываем решения, которые сами же и используем;</li> <li>stack: hadoop-3.1.x, kafka-2.4.x, spark-2.3.x, grafana 7.x, clickhouse, airflow</li> <li>lang: java, scala, python, bash.</li> </ul> <p><strong>Задачи:</strong></p> <ul> <li>развитие платформы хранения и обработки больших данных;</li> <li>внедрение новых инструментов для анализа данных / машинного обучения;</li> <li>разработка сервисов облегчающих работу data-science-специалистов;</li> <li>решение различных задач связанных с производительностью и отказоустойчивостью big-data-инфраструктуры;</li> <li>создание новых и поддержка рабочих пайплайнов - MapReduce, Spark, Samza;</li> <li>взаимодействие с командами DataScience и SRE;</li> <li>написание новой и дополнение уже имеющейся документации.</li> </ul> <p><strong>Требования:</strong></p> <ul> <li>готовность к самостоятельному обучению и постоянному развитию;</li> <li>понимание принципов работы локальных сетей и основных сетевых сервисов;</li> <li>знания принципов работы баз данных и распределенных систем хранения и обработки данных;</li> <li>знание Bash/Python для автоматизации процессов и Java/Scala для поддержки ETL и внедрения новых сервисов;</li> <li>опыт администрирования GNU/Linux, сборки пакетов и понимание принципов заложенных в Kerberos/SSL;</li> <li>опыт работы с системами мониторинга и инструментами для сбора метрик;</li> <li>опыт работы с со свежими версиями продуктов фонда Apache: Hadoop, Kafka, Spark, Zeppelin, Airflow, Zookeeper.</li> </ul> <p><strong>Условия:</strong></p> <ul> <li>сложные и интересные задачи: высоконагруженные быстрорастущие сервисы, которые задают уровень для конкурентов качеством и технологиями;</li> <li>оборудование: мощное железо, десятки петабайт данных, GPU-кластера и облачный инструментарий;</li> <li>команда: с нами работают профессионалы экстра класса, каждый из которых может поделиться своей экспертизой;</li> <li>профессиональное развитие: прямо в офисе мы организуем митапы, конференции, семинары и тренинги, куда открыт доступ каждому сотруднику, а также регулярно посещаем лучшие мировые конференции;</li> <li>новый опыт: лучшие сотрудники преподают в наших образовательных проектах, выступают на российских и международных конференциях;</li> <li>социальный пакет (питание, спорт, ДМС, английский язык);</li> <li>комфортный офис с парковкой, душем и зонами отдыха в паре минут от м. «Площадь Александра Невского»;</li> <li>дополнительное обучение за счет компании, участие в профессиональных конференциях и форумах по всему миру;</li> <li>корпоративные мероприятия и Team Building Events в России и за рубежом.</li> </ul></div>\n\t</div>\n\n ","vacancy_constructor_template":null,"key_skills":[{"name":"Spark"},{"name":"hadoop"},{"name":"Linux"},{"name":"kafka"},{"name":"airflow"},{"name":"grafana"}],"accept_handicapped":false,"accept_kids":false,"archived":false,"response_url":null,"specializations":[{"id":"1.221","name":"Программирование, Разработка","profarea_id":"1","profarea_name":"Информационные технологии, интернет, телеком"},{"id":"1.82","name":"Инженер","profarea_id":"1","profarea_name":"Информационные технологии, интернет, телеком"}],"code":null,"hidden":false,"quick_responses_allowed":false,"driver_license_types":[],"accept_incomplete_resumes":false,"employer":{"id":"15478","name":"Mail.ru Group","url":"https://api.hh.ru/employers/15478?host=hh.ru","alternate_url":"https://hh.ru/employer/15478","logo_urls":{"original":"https://hhcdn.ru/employer-logo-original/759103.png","90":"https://hhcdn.ru/employer-logo/3477369.png","240":"https://hhcdn.ru/employer-logo/3477370.png"},"vacancies_url":"https://api.hh.ru/vacancies?employer_id=15478&host=hh.ru","trusted":true},"published_at":"2020-11-12T15:36:21+0300","created_at":"2020-11-12T15:36:21+0300","negotiations_url":null,"suitable_resumes_url":null,"apply_alternate_url":"https://hh.ru/applicant/vacancy_response?vacancyId=39862488","has_test":false,"test":null,"alternate_url":"https://hh.ru/vacancy/39862488","working_days":[],"working_time_intervals":[],"working_time_modes":[],"accept_temporary":false}