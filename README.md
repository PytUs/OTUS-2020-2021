# OTUS-2020-2021
Hometasks
Здесь будут выложены домашние зработы по курсу DE на OTUS

3) Гид по безопасному Бостону
В этом задании предлагается собрать статистику по криминогенной обстановке в разных районах Бостона. В качестве исходных данных используется датасет
https://www.kaggle.com/AnalyzeBoston/crimes-in-boston
С помощью Spark соберите агрегат по районам (поле district) со следующими метриками:
●	crimes_total - общее количество преступлений в этом районе
●	crimes_monthly - медиана числа преступлений в месяц в этом районе
●	frequent_crime_types - три самых частых crime_type за всю историю наблюдений в этом районе, объединенных через запятую с одним пробелом “, ” , расположенных в порядке убывания частоты
○	crime_type - первая часть NAME из таблицы offense_codes, разбитого по разделителю “-” (например, если NAME “BURGLARY - COMMERICAL - ATTEMPT”, то crime_type “BURGLARY”)
●	lat - широта координаты района, расчитанная как среднее по всем широтам инцидентов
●	lng - долгота координаты района, расчитанная как среднее по всем долготам инцидентов
Программа должна упаковываться в uber-jar (с помощью sbt-assembly), и запускаться командой
spark-submit --master local[*] --class com.example.BostonCrimesMap /path/to/jar {path/to/crime.csv} {path/to/offense_codes.csv} {path/to/output_folder}
где {...} - аргументы, передаваемые пользователем.
Результатом её выполнения должен быть один файл в формате .parquet в папке path/to/output_folder.
Для джойна со справочником необходимо использовать broadcast.

Ссылку на репозиторий с кодом прислать в чат с преподавателем.

Методика оценки:
1.	Программа выдает корректный файл на выходе - 3 балла
2.	Здание сдано в течение 2 недель после публикации - 1 балл
3.	Задание сдано с первой попытки (повторные попытки из-за неточностей в условиях задания не считаются) - 1 балл

Вам могут пригодиться следующие материалы:
1.	Документация по Spark: https://spark.apache.org/docs/latest/
2.	Документация по SQL функциям Spark: https://spark.apache.org/docs/latest/api/sql/index.html

Подсказка: в спарке есть функция percentile_approx, которая может посчитать медиану.
Подсказка №2: не забывайте, что конкретный месяц идентифицируется не только номером месяца, но и номером года









































1)Домашнее задание: анализ рынка Инженер Данных: РФ, USA, EU
Цель: Изучить рынок Data Engineering и его особенности в РФ, EU, USA
Проанализировать требования к языкам, стеку инструментов и опыту
Поставить цели и акценты на обучение для себя
Источники: Glassdoor, HH, Monster, LinkedIn
Формат: Свободный - Google Doc, Jupyter, просто текст
Вопросы:
- Рынок DE: Количество вакансий, отрасли компаний, размер компаний
- Требования: Популярные языки, технологии, фреймворки
- Цели на обучение, акценты на интересующие темы и технологии
Критерии оценки: Наличие ответов на:
3 вопроса - 5 баллов
2 вопроса - 4 балла
1 вопрос - 3 балла
Рекомендуем сдать до: 09.12.2020


Примечания по примеру загрузки данных из HH:
Ограничивается не только парсерами, но и также можно посмотреть запросы Power Query внутри файла "ДЗ по HH Сводные данные парсинга".
Данные->Запросы и подключения->Выбираем запрос->Изменить->(чтобы посмотреть текст запроса)->Главная->Расширенный редактор.
Источник,откуда взяла парсер https://office-menu.ru/python/96-api-hh

Примечания по примеру ДЗ по источнику Monster:
Поверхностный анализ данных. Результат: текстовый файл с описанием.
