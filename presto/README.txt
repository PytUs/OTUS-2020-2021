Домашняя работа по HiveQL.

Необходимо выполнить запросы в Hive или Presto.

Цель:
Практика с Hive на GCP DataProc

План домашней работы: https://gist.github.com/kzzzr/f82e1511e8c38aa7d5c352a0ce308868
Что внутри:

конфигурируем окружение
создаем Metastore (MySQL), Dataproc (Хадуп-кластер)
загружаем датасет (Chicago Taxi Trips)
создаем таблицы, записываем данные в бинарный формат .parquet
работаем с данными через SQL (Hive, Presto, Pyspark)
Команды запускаем в командной строке GCP по порядку. В коде даны пояснительные комментарии по каждой команде.

Вопросы для домашнего задания:
Вывести динамику количества поездок помесячно
Вывести топ-10 компаний (company) по выручке (trip_total)
Подсчитать долю поездок <5, 5-15, 16-25, 26-100 миль
Ответы на эти вопросы (в виде выгрузки или скриншотов) нужно вложить в тред. Для ответа на эти вопросы потребуется сформировать SQL-запрос и выполнить его (в Hive или Presto).

Рекомендуем сдать до: 24.03.2021

Примечания:
1. Для избежания неверного чтения данных вместо timestamp применим string и далее извлечем нужную информацию.
2. Кластер по советам студентов в Slack был обновлен до версии 1.5, так как Cloud Shell не успевал за 20 мин обработать 
загрузку данных в parquet из csv.
3. Часть файлов csv удалялась также,как и в приложенном в задании репозитории.